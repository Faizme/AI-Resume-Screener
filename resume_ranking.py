import streamlit as st
from PyPDF2 import PdfReader
import pandas as pd
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Ensure necessary NLTK resources are downloaded
nltk_dependencies = [("corpora/stopwords", "stopwords"), ("tokenizers/punkt", "punkt")]
for path, dep in nltk_dependencies:
    try:
        nltk.data.find(path)
    except LookupError:
        nltk.download(dep)

stop_words = set(stopwords.words("english"))

# Streamlit page configuration
st.set_page_config(page_title="AI Resume Screening", layout="wide")

# Function to extract text from PDFs
def extract_text_from_pdf(file):
    try:
        pdf = PdfReader(file)
        text = " ".join([page.extract_text() or "" for page in pdf.pages])  # Handle None cases
        return text.strip()
    except Exception as e:
        return f"Error extracting text: {str(e)}"

# Function to preprocess text
def preprocess_text(text):
    text = text.lower()
    text = re.sub(f"[{string.punctuation}]", "", text)
    words = word_tokenize(text)
    words = [word for word in words if word not in stop_words and word.isalnum()]
    return " ".join(words)

# Function to rank resumes
def rank_resumes(job_description, resumes):
    processed_resumes = [preprocess_text(resume) for resume in resumes]
    processed_job_desc = preprocess_text(job_description)
    documents = [processed_job_desc] + processed_resumes
    vectorizer = TfidfVectorizer().fit_transform(documents)
    vectors = vectorizer.toarray()
    cosine_similarities = cosine_similarity([vectors[0]], vectors[1:]).flatten()
    return cosine_similarities

# Streamlit UI
st.title("üìÑ AI Resume Screening & Ranking System")
st.sidebar.header("‚ö° Features")

# About Section
st.sidebar.subheader("‚ÑπÔ∏è About")
st.sidebar.info(
    "**Developed by Mohammed Faiz**\n\n"
    "This application helps recruiters efficiently screen resumes based on job descriptions using AI. "
    "By utilizing Natural Language Processing (NLP) techniques, the system ranks resumes based on their relevance to the given job description. "
    "It also provides keyword analysis using word clouds to highlight essential skills and terms.\n\n"
    "üë®‚Äçüíª **About the Developer:**\n"
    "Mohammed Faiz is an aspiring software developer with expertise in Python, Java, C, HTML, CSS, JavaScript, and SQL. "
    "He has experience in data analysis, web development, and AI-driven applications. "
    "Connect with Faiz on [GitHub](https://github.com/Faizme) or [LinkedIn](https://www.linkedin.com/in/mohammed-faiz-me)."
)

# Job description input
st.header("üìù Job Description")
job_description = st.text_area("Enter the job description")

# File uploader
st.header("üìÇ Upload Resumes")
uploaded_files = st.file_uploader(
    "Upload resumes (PDF only)", type=["pdf"], accept_multiple_files=True
)

if uploaded_files and job_description:
    st.header("üìä Ranking Resumes")
    progress = st.progress(0)

    resumes = []
    for file in uploaded_files:
        text = extract_text_from_pdf(file)
        if text.startswith("Error extracting text"):
            st.error(f"‚ùå Failed to extract text from {file.name}")
        else:
            resumes.append(text)

    if resumes:
        progress.progress(50)
        scores = rank_resumes(job_description, resumes)
        progress.progress(100)

        results = pd.DataFrame({"Resume": [file.name for file in uploaded_files], "Score": scores})
        results = results.sort_values(by="Score", ascending=False)
        st.dataframe(results)

        if not results.empty:
            top_candidate = results.iloc[0]
            st.success(f"üèÜ Top Candidate: {top_candidate['Resume']} with Score: {top_candidate['Score']:.2f}")

        # Download results
        csv = results.to_csv(index=False)
        st.download_button("üì• Download Results as CSV", csv, "ranking_results.csv", "text/csv")

        # Word Cloud Visualization
        st.header("üì¢ Resume Keyword Analysis")
        all_text = " ".join(preprocess_text(resume) for resume in resumes)
        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)
        fig, ax = plt.subplots()
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis("off")
        st.pyplot(fig)s
